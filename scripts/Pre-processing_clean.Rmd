---
title: "Gobi: Pre-processing clean"
author: "Marie Hackenberg"
date: "2025-02-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Show overall start time
start_time_overall <- Sys.time()
cat("Starting pre-processing at ", format(start_time_overall, "%H:%M:%S"), "\n")
```

# Set number of trees for missForest here
```{r}
n_trees = 10
```

# Load libraries
```{r}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(missForest)
library(doParallel)
library(purrr)
```

# Load data: HUMET
```{r}
paths <- list(
  metabolon = "../input/raw/humet_data_raw_none_metablon.csv",
  biocrates = "../input/raw/humet_data_raw_none_biocrates.csv",
  inhouse = "../input/raw/humet_data_raw_none_in_house_biochemistry.csv",
#)
#paths_zscore <- list(
  z_metabolon = "../input/processed/humet_data_zscore_none_subjects15_tp57_m.csv",
  z_biocrates = "../input/processed/humet_data_zscore_none_subjects15_tp57_b.csv",
  z_inhouse = "../input/processed/humet_data_zscore_none_subjects15_tp57_i.csv"
)

# Read data into a list using purrr::map
data <- map(paths, read.csv, sep = ",", header = TRUE)
names(data) <- c("data_metabolon", "data_biocrates", "data_inhouse", "z_metabolon", "z_biocrates", "z_inhouse")

# Define platform names for each dataset
platform_names <- c(
  "Metabolon HD4 [nt-ms]",
  "Biocrates p150 [t-ms]",
  "In-house biochemistry [chem.]",
  "Metabolon HD4 [nt-ms]",
  "Biocrates p150 [t-ms]",
  "In-house biochemistry [chem.]"
)
```

# Prepare data
```{r}

# Add platform column
data <- map2(data, platform_names, ~.x %>%
               mutate(platform_name = .y) %>%
               select(platform_name, everything()) # platform name as first column
             )

# Add challenge column depending on time
add_challenge <- function(mydataset) {
  mydataset <- mydataset %>%
  mutate(challenge = case_when(
    time >= 1 & time <= 9 ~ "fasting",
    time >= 33 & time <= 39 ~ "exercise",
    time >= 40 & time <= 49 ~ "oltt",
    TRUE ~ NA_character_ # assign NA for any time outside ranges
    )) %>%
  dplyr::select(challenge, everything()) # make challenge the first column
  
  return(mydataset)
}

data <- map(data, add_challenge)

# Filter half the data for relevant timepoints only
relevant_timepoints <- function(mydataset) {
  
  #challenge_col <- names(mydataset)[1] 
  
  # Count the number of rows with NA in 'challenge' column before filtering
  rows_before <- nrow(mydataset)
  #rows_with_na <- sum(is.na(mydataset[[challenge_col]]))
  
  # Print the number of rows with NA (optional)
  #cat("Rows with NA in 'challenge' column:", rows_with_na, "\n")
  
  # mydataset <- mydataset %>%
  #   filter(!is.na(mydataset[[challenge_col]]))  # remove rows where 'challenge' (column 4 in pp) is NA
  
  mydataset$time <- as.numeric(as.character(mydataset$time))
  
  mydataset <- mydataset %>%
    filter(
      (time >= 1 & time <= 9) |   # fasting
      (time >= 33 & time <= 39) | # exercise
      (time >= 40 & time <= 49)   # oltt
    )
  
  # Calculate how many rows were removed
  rows_removed <- rows_before - nrow(mydataset)
  
  # Print the number of rows removed (optional)
  cat("Rows removed for dataset:", rows_removed, "\n")
  
  # Return the filtered dataset
  return(mydataset)
}

data[7:9] <- data[4:6]
data[10:12] <- data[4:6]
data[4:6] <- data[1:3]

data[1:3] <- map(data[1:3], relevant_timepoints)
data[7:9] <- map(data[7:9], relevant_timepoints)

names(data) <- c(
  "data_metabolon_ff", "data_biocrates_ff", "data_inhouse_ff",
  "data_metabolon_fl", "data_biocrates_fl", "data_inhouse_fl",
  "z_metabolon_ff", "z_biocrates_ff", "z_inhouse_ff",
  "z_metabolon_fl", "z_biocrates_fl", "z_inhouse_fl")
```

# Identify and remove artefacts
Filtering for outliers defined as data points beyond four standard deviations from the mean and for time points measured after the first 30 minutes of a study challenge, then inspecting manually before removing artefacts is already done in the downloaded dataset.

```{r}
# Prepare data
to_factor <- function(mydataset) {
  mydataset <- mydataset %>%
  mutate(
    challenge = as.factor(challenge),
    platform_name = as.factor(platform_name),
    time = as.numeric(as.character((time))),
    subject = as.factor(subject),
    )
  
  return(mydataset)
}

data <- map(data, to_factor)
```

## Exclude metabolites with more than 30% missing data points
```{r}
keep_sub_30 <- function(mydataset) {
  # Count total columns before filtering
  total_cols_before <- ncol(mydataset)
  
  # Identify columns with more than 30% missing values
  missing_threshold <- 0.3  # 30% threshold
  cols_to_keep <- colMeans(is.na(mydataset)) < missing_threshold | colnames(mydataset) == "challenge" # keep challenge column
  
  # Count total columns after filtering
  total_cols_after <- sum(cols_to_keep)
  
  # Filter the dataset to exclude high-missing-value columns
  mydataset <- mydataset[, cols_to_keep]
  
  # Calculate  number of removed columns
  removed_cols <- total_cols_before - total_cols_after
  
  # Print number of removed columns
  cat("Number of removed columns:", removed_cols, "\n")
  
  return(mydataset)
}

data <- map(data, keep_sub_30)
```

# Performing missForest
```{r}
mF_function <- function(mydataset, name) {
  start_time <- Sys.time()
  na_before <- sum(is.na(mydataset))
  cat(format(start_time, "%H:%M:%S"), "- NA in", name, "before:", na_before, "\n")
  
  # NECESSARY?
  # # Convert challenge column to factor if it is not already
  # if (is.character(dataset$challenge)) {
  #   dataset$challenge <- as.factor(dataset$challenge)
  # }
  
  if (na_before > 0) {
    cl <- makeCluster(detectCores() - 1, type = "FORK"); registerDoParallel(cl)
    mydataset <- missForest(mydataset, ntree = n_trees, parallelize = "variables", verbose = FALSE)$ximp
    stopCluster(cl)
  }
  
  end_time <- Sys.time()
  cat(format(end_time, "%H:%M:%S"), "- NA in", name, "- after:", sum(is.na(mydataset)), " (Time elapsed:", round(difftime(end_time, start_time, units = "mins"), 2), "min)\n\n")
  
  return(mydataset)
}

# Show start time
start_time_mF <- Sys.time()
cat("Starting missForest at ", format(start_time_mF, "%H:%M:%S"), "\n")

# Impute
data <- imap(data, mF_function)

# Show finish time and elasped time
end_time_mF <- Sys.time()
cat("Finished missForest at ", format(end_time_mF, "%H:%M:%S"), " (Time elapsed:", round(difftime(end_time_mF, start_time_mF, units = "mins"), 2), "min)\n")
```

# Log2 transform only the non-zscore data
```{r}
log2_transformed <- function(mydataset) {
  mydataset <- mydataset %>%
    mutate(time = as.factor(time)) %>% # refactor time column as factor to exclude from log2_transformation
    mutate(across(-c(1:4), log2))
  
  return(mydataset)
}

data[1:6] <- map(data[1:6], log2_transformed)
```

# Filter unfiltered data for relevant timepoints
```{r}


# Function already created in the beginning
data[4:6] <- map(data[4:6], relevant_timepoints)
data[10:12] <- map(data[10:12], relevant_timepoints)
```

# Save to a CSV file
```{r}
# Define output paths
output_names <- c(
  paste0("preproc_metabolon_ff_", as.character(n_trees)),
  paste0("preproc_biocrates_ff_", as.character(n_trees)),
  paste0("preproc_inhouse_ff_", as.character(n_trees)),
  paste0("preproc_metabolon_fl_", as.character(n_trees)),
  paste0("preproc_biocrates_fl_", as.character(n_trees)),
  paste0("preproc_inhouse_fl_", as.character(n_trees)),

  paste0("preproc_z_metabolon_ff_", as.character(n_trees)),
  paste0("preproc_z_biocrates_ff_", as.character(n_trees)),
  paste0("preproc_z_inhouse_ff_", as.character(n_trees)),
  paste0("preproc_z_metabolon_fl_", as.character(n_trees)),
  paste0("preproc_z_biocrates_fl_", as.character(n_trees)),
  paste0("preproc_z_inhouse_fl_", as.character(n_trees))
)

# Save each dataset as a named data frame in the environment
for (i in seq_along(data)) {
  assign(output_names[i], as.data.frame(data[[i]]), envir = .GlobalEnv)
}

# Write to csv
for (i in 1:length(data)) {
  # View(as.data.frame(data[[i]]))
  write.csv(data[[i]], paste0("../output/", output_names[i], ".csv"), row.names = FALSE) # row.names=false to only use existing rownames from here
}
```

# Merge non-z data into combined inputs for clustering
```{r}
# Merge by columns time and subject
preproc_raw_merged_ff <- get(output_names[1])[, -2] %>% # remove platform_name column for merging
  full_join(get(output_names[2])[, -2], by = c("challenge", "time", "subject")) %>%
  full_join(get(output_names[3])[, -2], by = c("challenge", "time", "subject"))

preproc_raw_merged_fl <- get(output_names[4])[, -2] %>%
  full_join(get(output_names[5])[, -2], by = c("challenge", "time", "subject")) %>%
  full_join(get(output_names[6])[, -2], by = c("challenge", "time", "subject"))
  
# Save to CSV
write.csv(preproc_raw_merged_ff, paste0("../output/preproc_raw_merged_ff_", n_trees, ".csv"), row.names = FALSE)
write.csv(preproc_raw_merged_fl, paste0("../output/preproc_raw_merged_fl_", n_trees, ".csv"), row.names = FALSE)
```

# Merge z-score data into combined inputs for clustering
```{r}
# Merge by columns time and subject
preproc_z_merged_ff <- get(output_names[7])[, -2] %>% # remove platform_name column for merging
  full_join(get(output_names[8])[, -2], by = c("challenge", "time", "subject")) %>%
  full_join(get(output_names[9])[, -2], by = c("challenge", "time", "subject"))

preproc_z_merged_fl <- get(output_names[10])[, -2] %>%
  full_join(get(output_names[11])[, -2], by = c("challenge", "time", "subject")) %>%
  full_join(get(output_names[12])[, -2], by = c("challenge", "time", "subject"))
  
# Save to CSV
write.csv(preproc_z_merged_ff, paste0("../output/preproc_z_merged_ff_", n_trees, ".csv"), row.names = FALSE)
write.csv(preproc_z_merged_fl, paste0("../output/preproc_z_merged_fl_", n_trees, ".csv"), row.names = FALSE)
```

```{r}
# Show overall finish time and elasped time
end_time_overall <- Sys.time()
cat("Finished pre-processing at ", format(end_time_overall, "%H:%M:%S"), " (Time elapsed:", round(difftime(end_time_overall, start_time_overall, units = "mins"), 2), "min)\n")
```

# End