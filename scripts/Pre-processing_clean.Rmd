---
title: "Gobi: Pre-processing clean"
author: "Marie Hackenberg"
date: "2025-02-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Show overall start time
start_time_overall <- Sys.time()
cat("Starting pre-processing at ", format(start_time_overall, "%H:%M:%S"), "\n")
```

# Set number of trees for missForest here
```{r}
n_trees = 1
```

# Load libraries
```{r}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(missForest)
library(doParallel)
library(purrr)
```

# Load data: HUMET
```{r}
paths <- list(
  metabolon = "../input/raw/humet_data_raw_none_metablon.csv",
  biocrates = "../input/raw/humet_data_raw_none_biocrates.csv",
  inhouse = "../input/raw/humet_data_raw_none_in_house_biochemistry.csv",
  z_metabolon = "../input/processed/humet_data_zscore_none_subjects15_tp57_m.csv",
  z_biocrates = "../input/processed/humet_data_zscore_none_subjects15_tp57_b.csv",
  z_inhouse = "../input/processed/humet_data_zscore_none_subjects15_tp57_i.csv"
)

# Read data into a list using purrr::map
data <- map(paths, read.csv, sep = ",", header = TRUE)
names(data) <- c("data_metabolon_ff", "data_biocrates_ff", "data_inhouse_ff", "z_metabolon_fl", "z_biocrates_fl", "z_inhouse_fl")

# Define platform names for each dataset
platform_names <- c(
  "Metabolon HD4 [nt-ms]",
  "Biocrates p150 [t-ms]",
  "In-house biochemistry [chem.]",
  "Metabolon HD4 [nt-ms]",
  "Biocrates p150 [t-ms]",
  "In-house biochemistry [chem.]"
)
```

# Prepare data
```{r}

# Add platform column
data <- map2(data, platform_names, ~.x %>%
               mutate(platform_name = .y) %>%
               select(platform_name, everything()) # platform name as first column
             )

# Add challenge column depending on time to one version
add_challenge <- function(dataset) {
  dataset <- dataset %>%
  mutate(challenge = case_when(
    time >= 1 & time <= 9 ~ "fasting",
    time >= 33 & time <= 39 ~ "exercise",
    time >= 40 & time <= 49 ~ "oltt",
    TRUE ~ NA_character_ # assign NA for any time outside ranges
    )) %>%
  dplyr::select(challenge, everything()) # make challenge the first column
  
  return(dataset)
}

data <- map(data, add_challenge)

# Filter half the data for relevant timepoints only
relevant_timepoints <- function(dataset) {
  
  challenge_col <- names(dataset)[1] 
  
  # Count the number of rows with NA in 'challenge' column before filtering
  rows_before <- nrow(dataset)
  rows_with_na <- sum(is.na(dataset[[challenge_col]]))
  
  # Print the number of rows with NA (optional)
  cat("Rows with NA in 'challenge' column:", rows_with_na, "\n")
  

  dataset <- dataset %>%
    filter(!is.na(.data[[challenge_col]]))  # remove rows where 'challenge' (column 4 in pp) is NA
  
  # Calculate how many rows were removed
  rows_removed <- rows_before - nrow(dataset)
  
  # Print the number of rows removed (optional)
  cat("Rows removed for dataset:", rows_removed, "\n")
  
  # Return the filtered dataset
  return(dataset)
}

data <- c(map(data[1:3], relevant_timepoints), data[1:3], map(data[4:6], relevant_timepoints), data[4:6])
```

# Identify and remove artefacts
Filtering for outliers defined as data points beyond four standard deviations from the mean and for time points measured after the first 30 minutes of a study challenge, then inspecting manually before removing artefacts is already done in the downloaded dataset.

```{r}
# Prepare data
to_factor <- function(dataset) {
  dataset <- dataset %>%
  mutate(
    challenge = as.factor(challenge),
    platform_name = as.factor(platform_name),
    time = as.numeric(as.character((time))),
    subject = as.factor(subject),
    )
  
  return(dataset)
}

data <- map(data, to_factor)
```

## Exclude metabolites with more than 30% missing data points
```{r}
keep_sub_30 <- function(dataset) {
  # Count total columns before filtering
  total_cols_before <- ncol(dataset)
  
  # Identify columns with more than 30% missing values
  missing_threshold <- 0.3  # 30% threshold
  cols_to_keep <- colMeans(is.na(dataset)) < missing_threshold | colnames(dataset) == "challenge" # keep challenge column
  
  # Count total columns after filtering
  total_cols_after <- sum(cols_to_keep)
  
  # Filter the dataset to exclude high-missing-value columns
  dataset <- dataset[, cols_to_keep]
  
  # Calculate  number of removed columns
  removed_cols <- total_cols_before - total_cols_after
  
  # Print number of removed columns
  cat("Number of removed columns:", removed_cols, "\n")
  
  return(dataset)
}

data <- map(data, keep_sub_30)
```

# Performing missForest
```{r}
mF_function <- function(dataset, name) {
  start_time <- Sys.time()
  na_before <- sum(is.na(dataset))
  cat(format(start_time, "%H:%M:%S"), "- NA in", name, "before:", na_before, "\n")
  
  # NECESSARY?
  # # Convert challenge column to factor if it is not already
  # if (is.character(dataset$challenge)) {
  #   dataset$challenge <- as.factor(dataset$challenge)
  # }
  
  if (na_before > 0) {
    cl <- makeCluster(detectCores() - 1, type = "FORK"); registerDoParallel(cl)
    dataset <- missForest(dataset, ntree = n_trees, parallelize = "variables", verbose = FALSE)$ximp
    stopCluster(cl)
  }
  
  end_time <- Sys.time()
  cat(format(end_time, "%H:%M:%S"), "- NA in", name, "- after:", sum(is.na(dataset)), " (Time elapsed:", round(difftime(end_time, start_time, units = "secs"), 2), "sec)\n\n")
  
  return(dataset)
}

# Show start time
start_time_mF <- Sys.time()
cat("Starting missForest at ", format(start_time_mF, "%H:%M:%S"), "\n")

# Impute
data <- imap(data, mF_function)

# Show finish time and elasped time
end_time_mF <- Sys.time()
cat("Finished missForest at ", format(end_time_mF, "%H:%M:%S"), " (Time elapsed:", round(difftime(end_time_mF, start_time_mF, units = "mins"), 2), "min)\n")
```

# Log2 transform only the non-zscore data
```{r}
log2_transformed <- function(dataset) {
  dataset <- dataset %>%
    mutate(time = as.factor(time)) %>% # refactor time column as factor to exclude from log2_transformation
    mutate(across(-c(1:4), log2))
  
  return(dataset)
}

data <- c(map(data[1:6], log2_transformed), data[7:12])
```

# Filter unfiltered data for relevant timepoints
```{r}
# Function already created in the beginning
data <- c(map(data[1:3], relevant_timepoints), data[4:6], map(data[7:9], relevant_timepoints), data[10:12])
```

# Save to a CSV file
```{r}
# Define output paths
output_names <- c(
  paste0("preproc_metabolon_ff_", as.character(n_trees)),
  paste0("preproc_biocrates_ff_", as.character(n_trees)),
  paste0("preproc_inhouse_ff_", as.character(n_trees)),
  paste0("preproc_metabolon_fl_", as.character(n_trees)),
  paste0("preproc_biocrates_fl_", as.character(n_trees)),
  paste0("preproc_inhouse_fl_", as.character(n_trees)),

  paste0("preproc_z_metabolon_ff_", as.character(n_trees)),
  paste0("preproc_z_biocrates_ff_", as.character(n_trees)),
  paste0("preproc_z_inhouse_ff_", as.character(n_trees)),
  paste0("preproc_z_metabolon_fl_", as.character(n_trees)),
  paste0("preproc_z_biocrates_fl_", as.character(n_trees)),
  paste0("preproc_z_inhouse_fl_", as.character(n_trees))
)

# Save each dataset as a named data frame in the environment
for (i in seq_along(data)) {
  assign(output_names[i], as.data.frame(data[[i]]), envir = .GlobalEnv)
}

# Write to csv
for (i in 1:length(data)) {
  # View(as.data.frame(data[[i]]))
  write.csv(data[[i]], paste0("../output/", output_names[i], ".csv"), row.names = FALSE) # row.names=false to only use existing rownames from here
}
```

```{r}
# Show overall finish time and elasped time
end_time_overall <- Sys.time()
cat("Finished pre-processing at ", format(end_time_overall, "%H:%M:%S"), " (Time elapsed:", round(difftime(end_time_overall, start_time_overall, units = "mins"), 2), "min)\n")
```

# End