---
title: "Gobi: Pre-processing clean"
author: "Marie Hackenberg"
date: "2025-02-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Show overall start time
```{r}
start_time_overall <- Sys.time()
cat("Starting pre-processing at ", format(start_time_overall, "%H:%M:%S"), "\n")
```

# Set number of trees for missForest here
```{r}
n_trees = 10
```

# Load libraries
```{r}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(missForest)
library(doParallel)
library(purrr)
```

# Load data: POSTPRANDIAL NON-IMPUTED and IMPUTED
```{r}
#paths <- list(
pp_path = "../input/raw/postprandial_non_imputed.csv"
pp_imputed_path = "../input/raw/postprandial_imputed.csv"
#)

# Read data into a list using purrr::map
pp <- read.csv(pp_path, sep = ";", header = TRUE)
pp_imp <- read.csv(pp_imputed_path, sep = ";", header = TRUE)

# Remove column X
pp <- pp[, !(names(pp) == "X")]
pp_imp <- pp_imp[, !(names(pp_imp) == "X")]

# Rename column challenge_time to time
pp <- pp %>%
  rename(time = challenge_time)
pp_imp <- pp_imp %>%
  rename(time = challenge_time)

# Values in metabolite columns as numeric with .
options(digits = 14)
num_met <- function(dataset) {
  dataset <- dataset %>%
  mutate(across(
    .cols = -c(subject, time, challenge),  # Exclude these columns
    .fns = ~ as.numeric(gsub(",", ".", .)),  # Replace commas with dots, convert to numeric, keep 14 decimals
    .names = "{.col}"  # Keep the original column names
  ))
  
  return(dataset)
}
pp <- num_met(pp)
pp_imp <- num_met(pp_imp)

# categorical columns as factor
cat_as_factor <- function(dataset) {
  dataset <- dataset %>%
  mutate(
    subject = as.factor(subject),
    time = as.factor(time),
    challenge = as.character(challenge)
  )

    return(dataset)
}

pp <- cat_as_factor(pp)
pp_imp <- cat_as_factor(pp_imp)
```

# De-log2 transform
```{r}
# Reverse the log2 transformation
pp <- pp %>%
  mutate(across(
    .cols = -c(subject, time, challenge),  # Exclude non-metabolite columns
    .fns = ~ 2^.,  # Reverse log2 by applying 2^x
    .names = "{.col}"  # Keep original column names
  ))
```

# Separate by platform
```{r}
metabolon_only <- function(dataset) {
  dataset <- bind_cols(platform_name = "Metabolon HD4 [nt-ms]", dataset[1:3], dataset %>%
  select(contains("_metabolon")) %>%
  rename_with(~ gsub("_metabolon$", "", .))) %>%
  mutate(
    platform_name = as.factor(platform_name)
  )
  return(dataset)
}
biocrates_only <- function(dataset) {
  dataset <- bind_cols(platform_name = "Biocrates p150 [t-ms]", dataset[1:3], dataset %>%
  select(contains("_biocrates")) %>%
  rename_with(~ gsub("_biocrates$", "", .))) %>%
  mutate(
    platform_name = as.factor(platform_name)
  )
    return(dataset)
}
inhouse_only <- function(dataset) {
  dataset <- bind_cols(platform_name = "In-house biochemistry [chem.]", dataset[1:3], dataset %>%
  select(contains("_biochemistry")) %>%
  rename_with(~ gsub("_biochemistry$", "", .))) %>%
  mutate(
    platform_name = as.factor(platform_name)
  )
    return(dataset)
}

# Create data list
data <- list(
  pp_metabolon = metabolon_only(pp),
  pp_biocrates = biocrates_only(pp),
  pp_inhouse = inhouse_only(pp)
)

data_imp <- list(
  pp_metabolon = metabolon_only(pp_imp),
  pp_biocrates = biocrates_only(pp_imp),
  pp_inhouse = inhouse_only(pp_imp)
)
```

# Prepare data
```{r}

# Filter half the data for relevant timepoints only
relevant_timepoints <- function(dataset) {
  challenge_col <- names(dataset)[4] 
  
  # Count the number of rows with NA in 'challenge' column before filtering
  rows_before <- nrow(dataset)
  rows_with_na <- sum(is.na(dataset[[challenge_col]]))
  
  dataset <- dataset %>%
    #mutate(challenge = as.character(challenge)) %>%
    filter(!is.na(.data[[challenge_col]]))  # remove rows where 'challenge' (column 4 in pp) is NA
  
  # Print the number of rows with NA (optional)
  cat("Rows with NA in 'challenge' column:", rows_with_na, "\n")
  
  # Calculate how many rows were removed
  rows_removed <- rows_before - nrow(dataset)
  
  # Print the number of rows removed (optional)
  cat("Rows removed for dataset:", rows_removed, "\n")
  
  # Return the filtered dataset
  return(dataset)
}

data <- c(map(data[1:3], relevant_timepoints), data[1:3])
```

# Identify and remove artefacts
Filtering for outliers defined as data points beyond four standard deviations from the mean and for time points measured after the first 30 minutes of a study challenge, then inspecting manually before removing artefacts is already done in the downloaded dataset.

```{r}
# Prepare data
to_factor <- function(dataset) {
  dataset <- dataset %>%
  mutate(
    challenge = as.factor(challenge),
    platform_name = as.factor(platform_name),
    time = as.numeric(as.character((time))),
    subject = as.factor(subject),
    )
  return(dataset) #added return
}

data <- map(data, to_factor)
data_imp <- map(data_imp, to_factor)
```

## Exclude metabolites with more than 30% missing data points
```{r}
keep_sub_30 <- function(dataset) {
  # Count total columns before filtering
  total_cols_before <- ncol(dataset)
  
  # Identify columns with more than 30% missing values
  missing_threshold <- 0.3  # 30% threshold
  cols_to_keep <- colMeans(is.na(dataset)) < missing_threshold | colnames(dataset) == "challenge" # keep challenge column
  
  # Count total columns after filtering
  total_cols_after <- sum(cols_to_keep)
  
  # Filter the dataset to exclude high-missing-value columns
  dataset <- dataset[, cols_to_keep]
  
  # Calculate  number of removed columns
  removed_cols <- total_cols_before - total_cols_after
  
  # Print number of removed columns
  cat("Number of removed columns:", removed_cols, "\n")
  
  return(dataset)
}

data <- map(data, keep_sub_30)
```

# Performing missForest
```{r}
# mF_function <- function(dataset) {
#   cat("NA in ",  deparse(substitute(dataset)), " before missForest:", sum(is.na(dataset)), "\n")
#   
#   if(!sum(is.na(dataset)) == 0) {
#     # Set up parallel backend using all available cores minus one
#     cl <- makeCluster(detectCores() - 1, type = "FORK")  # Use one less core to avoid overloading; Mac-specific "FORK" cluster type
#     registerDoParallel(cl)
#     
#     # Perform missForest imputation
#     set.seed(42)  # Ensures reproducibility
#     imputed_dataset <- missForest(dataset, ntree = 1, parallelize = "variables", verbose = "FALSE") # default ntree = 100; verbose=True to get progress messages              # ACHTUNG: DAUERT LANGE!!
#     
#     stopCluster(cl)  # Stop  cluster after imputation
#     
#     # Extract imputed dataset
#     imputed_dataset <- imputed_dataset$ximp
#   } else {
#     imputed_dataset <- dataset
#   }
#   cat("NA in ",  deparse(substitute(dataset)), " after missForest:", sum(is.na(imputed_dataset)), "\n\n\n")
#   
#   return(imputed_dataset)
# }
# 
# data <- map(data, mF_function)



mF_function <- function(dataset, name) {
  start_time <- Sys.time()
  na_before <- sum(is.na(dataset))
  cat(format(start_time, "%H:%M:%S"), "- NA in", name, "before:", na_before, "\n")
  
  # Convert challenge column to factor if it is not already
  if (is.character(dataset$challenge)) {
    dataset$challenge <- as.factor(dataset$challenge)
  }
  
  if (na_before > 0) {
    cl <- makeCluster(detectCores() - 1, type = "FORK"); registerDoParallel(cl)
    dataset <- missForest(dataset, ntree = n_trees, parallelize = "variables", verbose = FALSE)$ximp
    stopCluster(cl)
  }
  
  end_time <- Sys.time()
  cat(format(end_time, "%H:%M:%S"), "- NA in", name, "- after:", sum(is.na(dataset)), " (Time elapsed:", round(difftime(end_time, start_time, units = "secs"), 2), "sec)\n\n")
  
  return(dataset)
}

# Show start time
start_time_mF <- Sys.time()
cat("Starting missForest at ", format(start_time_mF, "%H:%M:%S"), "\n")

# Impute
data <- imap(data, mF_function)

# Show finish time and elasped time
end_time_mF <- Sys.time()
cat("Finished missForest at ", format(end_time_mF, "%H:%M:%S"), " (Time elapsed:", round(difftime(end_time_mF, start_time_mF, units = "mins"), 2), "min)\n")
```

# Log2 transform
```{r}
data_pre_log2 <- data

log2_transformed <- function(dataset) {
  dataset <- dataset %>%
    mutate(time = as.factor(time)) %>% # refactor time column as factor to exclude from log2_transformation
    mutate(across(
      
      # .cols = c(5:ncol(dataset)),  # Exclude the first 4 columns
      # .fns = ~ log2(as.numeric(.)),  # Apply log2 transformation
      # .names = "{.col}"
      
      -c(1:4), log2
    ))
  return(dataset) #added return
}


data_post_log2 <- map(data, log2_transformed)
data <- data_post_log2
```


# Filter unfiltered data for relevant timepoints
```{r}
# relevant_timepoints <- function(dataset) {
#   dataset %>%
#     filter(!is.na(challenge))  # remove rows where 'challenge' is NA
# }

# Already created at beginning
# relevant_timepoints <- function(dataset) {
#   # Find the column that contains 'challenge'
#   #challenge_col <- names(dataset)[1]
#   
#   # if (length(challenge_col) == 0) {
#   #   stop("No challenge column found in dataset")
#   # }
#   
#   dataset %>%
#     filter(!is.na(.data[[names(dataset)[1]]]))  # Dynamically filter based on the actual column name
#   return(dataset) #added return
# }

data <- c(map(data[1:3], relevant_timepoints), data[4:6])
```
# Clean column names
```{r}
# cols_names <- function(dataset) {
#   # Standardize column names by removing filename prefixes
#   cleaned_dataset <- dataset %>%
#     rename_with(~ str_remove(., ".*_"))  # Remove everything before and including "_"
# 
# }
# 
# data <- map(data, cols_names)
```

# Save to a CSV file
```{r}
# Define output paths
output_names <- c(
  paste0("pp_preproc_metabolon_filtered_first_", as.character(n_trees)),
  paste0("pp_preproc_biocrates_filtered_first_", as.character(n_trees)),
  paste0("pp_preproc_inhouse_filtered_first_", as.character(n_trees)),
  paste0("pp_preproc_metabolon_filtered_last_", as.character(n_trees)),
  paste0("pp_preproc_biocrates_filtered_last_", as.character(n_trees)),
  paste0("pp_preproc_inhouse_filtered_last_", as.character(n_trees))
)
imp_output_names <- c(
  "pp_imp_metabolon",
  "pp_imp_biocrates",
  "pp_imp_inhouse"
)

# Save each dataset as a named data frame in the environment
for (i in seq_along(data)) {
  assign(output_names[i], as.data.frame(data[[i]]), envir = .GlobalEnv)
}

for (i in seq_along(data_imp)) {
  assign(imp_output_names[i], as.data.frame(data_imp[[i]]), envir = .GlobalEnv)
}

# Write to csv
for (i in 1:length(data)) {
  # View(as.data.frame(data[[i]]))
  write.csv(data[[i]], paste0("../output/", output_names[i], ".csv"), row.names = FALSE) # row.names=false to only use existing rownames from here
}
```

```{r}
# Show overall finish time and elasped time
end_time_overall <- Sys.time()
cat("Finished pre-processing at ", format(end_time_overall, "%H:%M:%S"), " (Time elapsed:", round(difftime(end_time_overall, start_time_overall, units = "mins"), 2), "min)\n")
```


# End