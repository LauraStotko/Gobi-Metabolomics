---
title: "Gobi: Pre-processing"
author: "Marie Hackenberg"
date: "2025-02-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load libraries
```{r}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(missForest)
library(doParallel)
```

# Load data
```{r}
#data_path <- "../data/raw/humet_data_raw_none_subjects15_tp57.csv"
path_metabolon <- "../data/raw/humet_data_raw_none_metablon.csv"
path_biocrates <- "../data/raw/humet_data_raw_none_biocrates.csv"
path_inhouse <- "../data/raw/humet_data_raw_none_in_house_biochemistry.csv"
info_path <- "../data/raw/humet_info.csv"
#data_raw <- read.csv(data_path, sep = ",", header = TRUE)
data_metabolon <- read.csv(path_metabolon, sep = ",", header = TRUE)
data_biocrates <- read.csv(path_biocrates, sep = ",", header = TRUE)
data_inhouse <- read.csv(path_inhouse, sep = ",", header = TRUE)
info <- read.csv(info_path, sep = ",", header = TRUE)

# Add platform column
data_metabolon <- cbind(platform = "Metabolon HD4 [nt-ms]", data_metabolon)
data_biocrates <- cbind(platform = "Biocrates p150 [t-ms]", data_biocrates)
data_inhouse <- cbind(platform = "In-house biochemistry [chem.]", data_inhouse)

# Add challenge column depending on time
add_challenge <- function(data) {
  data %>%
  mutate(challenge = case_when(
    time >= 1 & time <= 9 ~ "fasting",      # time 1-10 corresponds to fasting
    time >= 33 & time <= 39 ~ "exercise",    # time 33-39 corresponds to exercise
    time >= 40 & time <= 49 ~ "oltt",        # time 40-48 corresponds to OLTT
    TRUE ~ NA_character_                                            # assign NA for any time outside ranges
    )) %>%
  filter(!is.na(challenge)) %>%  # remove rows where 'challenge' is NA
  dplyr::select(challenge, everything()) # make challenge the first column
}

data_metabolon <- add_challenge(data_metabolon)
data_biocrates <- add_challenge(data_biocrates)
data_inhouse <- add_challenge(data_inhouse)

# Keep only plasma info
info <- info %>% filter(fluid == "plasma")
```
# Pre-processing

Next, filter for time points measured after the first 30 minutes of a study challenge. Then, filter for outliers defined as data points beyond four standard deviations from the mean. The order is crucial, as filtering first for outliers and then for time points could exclude too many time points that are outliers simply *because* they stem from the first thirty minutes.

#todoxxx: identify minutes data. Oder sowieso schon auf outlier getreated wgene 'concentrations and relative abundances'? Dann nur missForest

# SKIP OUTLIER IDENTIFICATION FOR NOW

## First 30mins Then 4 SD from mean #todo: for each challenge separately
```{r}
# # Filter for time points within first 30 mins
# data_after_30min <- data %>% filter(time > 30)
# 
# # Filter for outliers based on standard deviation
# identify_outliers <- function(metabolite_data){
#   mean_value <- mean(metabolite_data, na.rm = TRUE)
#   sd_value <- sd(metabolite_data, na.rm = TRUE)
#   
#   # Outliers defined as data points beyond 4 SD from mean
#   outliers <- metabolite_data > (mean_value + 4 * sd_value) | metabolite_data < (mean_value - 4 * sd_value)
#   
#   return(outliers)
# }
# 
# # Apply outliers function to each metabolite column, excluding subject and challenge_time
# outliers_data_after_30min <- data_after_30min %>%
#   select(-subject, -time, -challenge) %>% # remove subject and challenge_time
#   apply(2, identify_outliers) # apply outlier detection for each metabolite, "2" for column
# 
# # Check how many outliers (TRUE)
# table(outliers_data_after_30min)

```
122 data points fit both time and outlier criteria and require manual inspection.

## SKIP FOR NOW

## First 4 SD from mean Then 30mins
```{r}
# # Apply outliers function to each metabolite column, excluding subject and challenge_time
# outliers_data <- data %>%
#   select(-subject, -time, -challenge) %>% # remove subject and challenge_time
#   apply(2, identify_outliers) # apply outlier detection for each metabolite, "2" for column
# outliers_data <- as.data.frame(outliers_data)
# outliers_data$time <- data$time
# 
# # Filter for time points within first 30 mins
# after_30min_outliers_data <- outliers_data %>% filter(time > 30)
# 
# # Check how many outliers (TRUE)
# dim(after_30min_outliers_data)
# #table(after_30min_outliers_data)
# true_count_total <- sum(after_30min_outliers_data == TRUE, na.rm = TRUE)
# 
# # Count FALSE values for each column
# false_count_total <- sum(after_30min_outliers_data == FALSE, na.rm = TRUE)
# 
# # Print results
# cat("Total FALSE values:", false_count_total, "\n")
# cat("Total TRUE values:", true_count_total, "\n")

```
Using outliers_data_after_30min for now, with 122 True

## SKIP FOR NOW

## Manual inspection
```{r}
# # Combine outlier data with subject and challenge time for manual inspection
# outliers_data_df <- as.data.frame(outliers_data_after_30min) # convert to dataframe
# 
# metabolite_columns <- data_after_30min %>%
#   select(-subject, -time, -challenge) %>%
#   colnames()
# colnames(outliers_data_df) <- metabolite_columns
# 
# table(unlist(outliers_data_df))
```
## SKIP FOR NOW

## Check for unique subjects per time point, challenge, and metabolite
```{r}
# outliers_data_df <- outliers_data_df %>%
#   mutate(across(everything(), ~ as.logical(.))) # ensure rue/false values
# 
# # Add non-metabolite columns back
# outliers_data_df$subject <- data_after_30min$subject
# outliers_data_df$time <- data_after_30min$time
# outliers_data_df$challenge <- data_after_30min$challenge
# 
# # Pivot dataframe into long format
# outliers_long <- outliers_data_df %>%
#   mutate(subject = data_after_30min$subject,
#          time = data_after_30min$time,
#          challenge = data_after_30min$challenge) %>%
#   pivot_longer(
#     cols = -c(subject, time, challenge), # keep subject, time, and challenge; make all metabolites long
#     names_to = "metabolite",
#     values_to = "is_outlier"
#   ) %>%
#   filter(is_outlier == TRUE) # keep only outlier rows
# 
# # Count unique subjects for each metabolite, time, and challenge
# outlier_counts <- outliers_long %>%
#   group_by(metabolite, time, challenge) %>%
#   summarise(unique_subjects = n_distinct(subject), .groups = "drop") %>% # count unique subjects; "drop" for clean dataframe
#   arrange(metabolite, time, challenge) # order results
# 
# # Identify individual subjects that had an outlier at each time for given metabolite
# single_subject_outliers <- outlier_counts %>%
#   filter(unique_subjects == 1) # keep only cases where **one** subject has outlier
```
Exclude (i.e. set to missing) the identified unique subjects per time point, challenge, and metabolite from further analysis.




# Impute missing values using missForest

```{r}
# Prepare data
#data <- data %>%
 # mutate(across(where(is.character), as.factor))

to_factor <- function(dataset) {
  dataset %>%
  mutate(
    challenge = as.factor(challenge),
    platform = as.factor(platform),
    time = as.factor(time),
    subject = as.factor(subject),
    ) %>%
  mutate(across(where(is.character), as.factor)) # should not make a difference. #del if possible
}

data_metabolon <- to_factor(data_metabolon)
data_biocrates <- to_factor(data_biocrates)
data_inhouse <- to_factor(data_inhouse)
```

## Exclude metabolites with more than 30% missing data points
```{r}
keep_sub_30 <- function(dataset) {
  # Count total columns before filtering
  total_cols_before <- ncol(dataset)
  
  # Identify columns with more than 30% missing values
  missing_threshold <- 0.3  # 30% threshold
  cols_to_keep <- colMeans(is.na(dataset)) < missing_threshold
  
  # Count total columns after filtering
  total_cols_after <- sum(cols_to_keep)
  
  # Filter the dataset to exclude high-missing-value columns
  dataset <- dataset[, cols_to_keep]
  
  # Calculate  number of removed columns
  removed_cols <- total_cols_before - total_cols_after
  
  # Print number of removed columns
  cat("Number of removed columns:", removed_cols, "\n")
  
  return(dataset)
}

data_metabolon <- keep_sub_30(data_metabolon)
data_biocrates <- keep_sub_30(data_biocrates)
data_inhouse <- keep_sub_30(data_inhouse)

cat("Number of NA in data_metabolon:", sum(is.na(data_metabolon)), "\n")
cat("Number of NA in data_biocrates:", sum(is.na(data_biocrates)), "\n")
cat("Number of NA in data_inhouse:", sum(is.na(data_inhouse)), "\n")

```

```{r}
# # Clean up metabolite names
# 
# # Remove everything starting from '(' and after, including any spaces before '('
# info$metabolite_clean <- gsub("\\s\\([^)]*\\)\\s?\\*?", "", info$metabolite)
# info$metabolite_clean <- gsub("\\s?\\*?", "", info$metabolite_clean)
# info$metabolite_clean <- gsub("-", "\\.", info$metabolite_clean)
# info$metabolite_clean <- gsub("\\(", "\\.", info$metabolite_clean)
# info$metabolite_clean <- gsub("\\)", "\\.", info$metabolite_clean)
# 
# # Reorder columns to make 'metabolite_clean' the first column
# info <- info[, c("metabolite_clean", setdiff(names(info), "metabolite_clean"))]
# 
# col_name <- "X3.carboxy.4.methyl.5.propyl.2.furanpropanoate..CMPF...P..nt.ms."
# new_col_name <- gsub("\\.\\.P\\.1?.*", "", col_name)
# new_col_name <- gsub("X", "", new_col_name)
# new_col_name

```


```{r}
# 
# 
# # Map metabolite column names in data to platform name
# metabolite_columns <- colnames(data[, 4:ncol(data)])
# platform_info <- info %>% 
#   filter(metabolite %in% metabolite_columns)
# 
# # Separate data by platform
# data_fasting <- data %>% filter(challenge == "fasting")
# data_exercise <- data %>% filter(challenge == "exercise")
# data_oltt <- data %>% filter(challenge == "oltt")

```

## Perform missforest on METABOLON data
```{r}
cat("NA in metabolon before missForest:", sum(is.na(data_metabolon)), "\n")
if(!sum(is.na(data_metabolon)) == 0) {
  # Set up parallel backend using all available cores minus one
  cl <- makeCluster(detectCores() - 1, type = "FORK")  # Use one less core to avoid overloading; Mac-specific "FORK" cluster type
  registerDoParallel(cl)
  
  # Perform missForest imputation
  set.seed(42)  # Ensures reproducibility
  imputed_metabolon <- missForest(data_metabolon, ntree = 10, parallelize = "variables", verbose = "TRUE") # default ntree = 100; verbose=True to get progress messages              # ACHTUNG: DAUERT LANGE!!
  
  stopCluster(cl)  # Stop  cluster after imputation
  
  # Check imputation error
  imputed_metabolon$error
  summary(imputed_metabolon)
  sum(is.na(imputed_metabolon))
  
  # Extract imputed dataset
  imputed_metabolon <- imputed_metabolon$ximp
} else {
  imputed_metabolon <- data_metabolon
}
cat("NA in metabolon after missForest:", sum(is.na(imputed_metabolon)), "\n")
```

```{r}
# # TEMPORARY
# data_rf_path <- "../data/processed/humet_data_raw_rf_subjects15_tp57.csv"
# data_rf <- read.csv(data_rf_path, sep = ",", header = TRUE)
```



## Perform missforest on BIOCRATES data
```{r}
cat("NA in biocrates before missForest:", sum(is.na(data_biocrates)), "\n")
if(!sum(is.na(data_biocrates)) == 0) {
  # Set up parallel backend using all available cores minus one
  cl <- makeCluster(detectCores() - 1, type = "FORK")  # Use one less core to avoid overloading; Mac-specific "FORK" cluster type
  registerDoParallel(cl)
  
  # Perform missForest imputation
  set.seed(42)  # Ensures reproducibility
  imputed_biocrates <- missForest(data_biocrates, ntree = 10, parallelize = "variables", verbose = "TRUE") # default ntree = 100; verbose=True to get progress messages              # ACHTUNG: DAUERT LANGE!!
  
  stopCluster(cl)  # Stop  cluster after imputation
  
  # Check imputation error
  imputed_biocrates$error
  summary(imputed_biocrates)
  sum(is.na(imputed_biocrates)) 
  
  # Extract imputed dataset
  imputed_biocrates <- imputed_biocrates$ximp
} else {
  imputed_biocrates <- data_biocrates
}
cat("NA in biocrates after missForest:", sum(is.na(imputed_biocrates)), "\n")
```

## Perform missforest on IN-HOUSE data
```{r}
cat("NA in in-house before missForest:", sum(is.na(data_inhouse)), "\n")
if(!sum(is.na(data_inhouse)) == 0) {
  # Set up parallel backend using all available cores minus one
  cl <- makeCluster(detectCores() - 1, type = "FORK")  # Use one less core to avoid overloading; Mac-specific "FORK" cluster type
  registerDoParallel(cl)
  
  # Perform missForest imputation
  set.seed(42)  # Ensures reproducibility
  imputed_inhouse <- missForest(data_inhouse, ntree = 10, parallelize = "variables", verbose = "TRUE") # default ntree = 100; verbose=True to get progress messages              # ACHTUNG: DAUERT LANGE!!
  
  stopCluster(cl)  # Stop  cluster after imputation
  
  # Check imputation error
  imputed_inhouse$error
  summary(imputed_inhouse)
  sum(is.na(imputed_inhouse)) 
  
  # Extract imputed dataset
  imputed_inhouse <- imputed_inhouse$ximp
} else {
  imputed_inhouse <- data_inhouse
}
cat("NA in in-house after missForest:", sum(is.na(imputed_inhouse)), "\n")
```

# Recombine three challenges into one dataset
```{r}
# Combine imputed challenge datasets
imputed_data_complete <- bind_rows(imputed_metabolon, imputed_biocrates, imputed_inhouse)
sum(is.na(imputed_data_complete)) #todo: NAs
```

# Log2 Transform
```{r}
imputed_log2_data_complete <- imputed_data_complete %>%
  mutate(across(where(is.numeric), log2))
```


```{r}

# Save to a CSV file
write.csv(imputed_data_complete, "../figures/imputed_complete.csv", row.names = FALSE)

```

```{r}

```


```{r}

```


```{r}

```


```{r}

```

